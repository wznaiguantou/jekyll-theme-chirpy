---
layout: post
title:  "Kafka笔记"
date:   2022-01-19 00:27:58 +0800
categories: Kafka
---

## 1. 分区器

通过key 计算出一个散列值，并映射到具体的分区。 那么相同的key需要一定计算出相同的散列值。

**_如果我扩展了分区，我该怎么办，原来的这些key的散列值可能已经不一样了，我还能留到第一个分区么？_**

**<font color=red>那换个问题，我为什么要保证原来的key在同样的那个分区呢？</font>**

> 消费者把每个分区最后读取的消息偏移量保存在Zookeeper或Kafka上，如果消费者关闭或重启，它的读取状态不会丢失。

 这里讲的是offset会维护在kafka 或者zk上，老版本是zk, 新版本是Kafka.

> 消费者是消费者群组的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消费者使用，在群组中，有3个消费者同时读取一个主题。其中的两个消费者各自读取一个分区，另外一个消费者读取其他两个分区。消费者与分区之间的映射通常被称为消费者对分区的所有权关系。

那么问题来了。 为什么一个分区只能被一个消费者消费，不可以有多个消费者么？这样不是可以更快的消费消息么？

因为在kafka中，一个分区的消息是有序的，是靠一个**自增长**（是自增长的么？我瞎说的，但是应该是）的offset来进行标记消费到哪里了。那如果存在1个以上的消费者A、B，如果B 的offset=2，A的offset =1，那么假设A 消费失败了，B 消费成功且ack了, 那么A 这条offset的消息就丢失了。



## Kafka的概念模型

Kafka是基于消费-生产者模型的事件流平台，

1. 生产者



2. 消费者

   - 消费者还可以成为一个消费群体，消费组

3. Broker（节点）

   > 一个独立的Kafka服务器被称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。根据特定的硬件及其性能特征，单个broker可以轻松处理数千个分区以及每秒百万级的消息量。

所以从这段话看出了，Kafka 的单个节点干了几件事情。

- 收到producer的消息，设置offset。

- 消息会被broker处理存储到磁盘上。

- Consumer 会找broker 要消息。 （这里有个前提。是consumer要消息所处分区的 leader 分区）。

  - **_这里有点疑惑？ 就是consumer 知道哪个分区的leader 是谁么？_**

- 根据硬件和其性能特指，可以轻松处理千个分区和每秒百万级的消息量

  - 这里问题又来了。这百万级的消息有消息大小限制么？ 难到1G的消息也支持每秒百万级么

  > broker是集群的组成部分。每个集群都有一个broker同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。控制器负责管理工作，包括将分区分配给broker和监控broker。在集群中，一个分区从属于一个broker，该broker被称为分区的首领。

- 这里在Kafak 集群上，都会存在一个broker 充当Controller的作用，用来分配分区和监控Broker.



## 基于什么原因，需要多Kafka集群

- 灾备
- 数据类型分类
- 安全需求隔离

在多集群里，怎么处理数据的一致性问题。

### MirrorMaker

> MirrorMaker的核心组件包含了一个生产者和一个消费者，两者之间通过一个队列相连。消费者从一个集群读取消息，生产者把消息发送到另一个集群上



<img src="https://res.weread.qq.com/wrepub/epub_27337544_14" alt="多集群分区" style="zoom:67%;" />

<center><p>多数据中心架构</p></center>

## Partition分区数量的选择

> 为主题选定分区数量并不是一件可有可无的事情，在进行数量选择时，需要考虑如下几个因素。
>
> - 主题需要达到多大的吞吐量？例如，是希望每秒钟写入100KB还是1GB？
> - 从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费者，如果你知道消费者将数据写入数据库的速度不会超过每秒50MB，那么你也该知道，从一个分区读取数据的吞吐量不需要超过每秒50MB。
> - 可以通过类似的方法估算生产者向单个分区写入数据的吞吐量，不过生产者的速度一般比消费者快得多，所以最好为生产者多估算一些吞吐量。
> - 每个broker包含的分区个数、可用的磁盘空间和网络带宽。
> - 如果消息是按照不同的键来写入分区的，那么为已有的主题新增分区就会很困难。
> - 单个broker对分区个数是有限制的，因为分区越多，占用的内存越多，完成首领选举需要的时间也越长。
>
> 很显然，综合考虑以上几个因素，你需要很多分区，但不能太多。如果你估算出主题的吞吐量和消费者吞吐量，可以用主题吞吐量除以消费者吞吐量算出分区的个数。也就是说，如果每秒钟要从主题上写入和读取1GB的数据，并且每个消费者每秒钟可以处理50MB的数据，那么至少需要20个分区。这样就可以让20个消费者同时读取这些分区，从而达到每秒钟1GB的吞吐量。

这里表述了2个内容

吞吐量:  

你对系统的吞吐量预期，对producer的吞吐量的预期，对consumer的吞吐量的预期。

可以先简单的得出 分区数

硬、软件限制：

分区的多少对broker是存在影响的。 分区越多，对Leader的选择耗时越长。 

思考一个问题, 为什么会越长,是什么原因导致的？

因为broker 中的leader分区需要重新选主。

***<font color=red> 吞吐量的定义是什么</font>***

单位时间内，完成了多少次某些事情，比如请求数、字节数。

***<font color=red> 吞吐量的计算公式</font>***

## Kafka日志的过期策略

这里倒是有一个有点意思的重点:

> 如果主题的消息量不大，那么如何调整这个参数的大小就变得尤为重要。例如，如果一个主题每天只接收100MB的消息，而log.segment.bytes使用默认设置，那么需要10天时间才能填满一个日志片段。因为在日志片段被关闭之前消息是不会过期的，所以如果log. retention.ms被设为604800 000（也就是1周），那么日志片段最多需要17天才会过期。这是因为关闭日志片段需要10天的时间，而根据配置的过期时间，还需要再保留7天时间（要等到日志片段里的最后一个消息过期才能被删除）

所以如果一个主题的体量比较小，可以调控log.segement.bytes来触发7天的效率。但是这个参数会影响其他的主题设置。

所以7天删除并不是一个绝对值，是在这个Segement文件被关闭后，才会开始计时。



## Kafka环境考虑点

- 硬件层面
  - 磁盘吞吐量
    - 磁盘阵列
    - SSD
  - 内存大小
    - Kafka 吞吐量高的原因之一就有靠系统的 Page Cache
    - 
- 网络吞吐量
  - 修改socket的Read-Write buffer 来加速
- 软件层面
  - 基于JVM的，所以存在垃圾回收，这里可以考虑垃圾回收器的选择。
  - 



## Kafka Producer

这里就不在赘述 一个生产者的发送流程了，请在最后补充2张图。

另外请再思考一个点，producer是通过分区器算出了具体的发生分区，那么是通过Kafka 集群的元数据得知具体的分区leader的么？然后对着这个leader进行发送，

在扩展一点思考点：这里是不是和ES的转发机制不一样了。

<font color=red>完整的Kafka 发送消息的图</font>

<font color=red>producer类图，描述清楚职责关系</font>



## 第5章 Core content

这里讲了Kafka 中的broker, controller的一些核心理论。

1. Broker 中的leader replica ，客户端只能对着replica leader 进行通信，否则会报错，认为是客户端获取的元数据是过期的。

2. 当前replica leader 不一定是first leader(书上描述的是首选首领)，这里还是要看下英文版的文档来看下原文是什么样的

3. 请求处理过程中一些常规、细节的点，

   - 会进行一些参数校验，比如producer的ack 参数对不对，发送到的broker是不是副本leader，

4. 为了节约开销，调优，我们是否需要对不太持续变化的内容设定最小消息大小限定，降低IO的次数。但是这样会产生延迟么？比如一个消息的大小很小，但是需要很及时，这个时候我调优的意义就不太存在了，比如告警规则的创建、更新动作。

   ***<font color=yellow>我觉得我们对Kafka的客户端还是用的太随意了。</font>***





