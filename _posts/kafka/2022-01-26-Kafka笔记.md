---
layout: post
title:  "Kafka笔记"
date:   2022-01-19 00:27:58 +0800
categories: Kafka
---
## 1. 分区器

通过key 计算出一个散列值，并映射到具体的分区。 那么相同的key需要一定计算出相同的散列值。

**_如果我扩展了分区，我该怎么办，原来的这些key的散列值可能已经不一样了，我还能留到第一个分区么？_**

**<font color=red>那换个问题，我为什么要保证原来的key在同样的那个分区呢？</font>**

> 消费者把每个分区最后读取的消息偏移量保存在Zookeeper或Kafka上，如果消费者关闭或重启，它的读取状态不会丢失。

 这里讲的是offset会维护在kafka 或者zk上，老版本是zk, 新版本是Kafka.

> 消费者是消费者群组的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消费者使用，在群组中，有3个消费者同时读取一个主题。其中的两个消费者各自读取一个分区，另外一个消费者读取其他两个分区。消费者与分区之间的映射通常被称为消费者对分区的所有权关系。

那么问题来了。 为什么一个分区只能被一个消费者消费，不可以有多个消费者么？这样不是可以更快的消费消息么？

因为在kafka中，一个分区的消息是有序的，是靠一个**自增长**（是自增长的么？我瞎说的，但是应该是）的offset来进行标记消费到哪里了。那如果存在1个以上的消费者A、B，如果B 的offset=2，A的offset =1，那么假设A 消费失败了，B 消费成功且ack了, 那么A 这条offset的消息就丢失了。



## Kafka的概念模型

Kafka是基于消费-生产者模型的事件流平台，

1. 生产者



2. 消费者

   - 消费者还可以成为一个消费群体，消费组

3. Broker（节点）

   > 一个独立的Kafka服务器被称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。根据特定的硬件及其性能特征，单个broker可以轻松处理数千个分区以及每秒百万级的消息量。

所以从这段话看出了，Kafka 的单个节点干了几件事情。

- 收到producer的消息，设置offset。

- 消息会被broker处理存储到磁盘上。

- Consumer 会找broker 要消息。 （这里有个前提。是consumer要消息所处分区的 leader 分区）。

  - **_这里有点疑惑？ 就是consumer 知道哪个分区的leader 是谁么？_**

- 根据硬件和其性能特指，可以轻松处理千个分区和每秒百万级的消息量

  - 这里问题又来了。这百万级的消息有消息大小限制么？ 难到1G的消息也支持每秒百万级么

  > broker是集群的组成部分。每个集群都有一个broker同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。控制器负责管理工作，包括将分区分配给broker和监控broker。在集群中，一个分区从属于一个broker，该broker被称为分区的首领。

- 这里在Kafak 集群上，都会存在一个broker 充当Controller的作用，用来分配分区和监控Broker.



## 基于什么原因，需要多Kafka集群

- 灾备
- 数据类型分类
- 安全需求隔离

在多集群里，怎么处理数据的一致性问题。

### MirrorMaker

> MirrorMaker的核心组件包含了一个生产者和一个消费者，两者之间通过一个队列相连。消费者从一个集群读取消息，生产者把消息发送到另一个集群上



<img src="https://res.weread.qq.com/wrepub/epub_27337544_14" alt="多集群分区" style="zoom:67%;" />

<center><p>多数据中心架构</p></center>

